{
 "metadata": {
  "name": "",
  "signature": "sha256:21f634d408697f5913dff89c5f28655d9432f57fd7630b1fb34867f37d4caecd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import string\n",
      "import urllib2\n",
      "from pprint import pprint\n",
      "import re\n",
      "import scrapy\n",
      "from scrapy.selector import Selector\n",
      "from scrapy.http import HtmlResponse\n",
      "import unicodedata"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from HTMLParser import HTMLParser\n",
      "\n",
      "class MLStripper(HTMLParser):\n",
      "    def __init__(self):\n",
      "        self.reset()\n",
      "        self.fed = []\n",
      "    def handle_data(self, d):\n",
      "        self.fed.append(d)\n",
      "    def get_data(self):\n",
      "        return ''.join(self.fed)\n",
      "\n",
      "def strip_tags(html):\n",
      "    s = MLStripper()\n",
      "    s.feed(html)\n",
      "    return s.get_data()\n",
      "\n",
      "def getNouns(arr):\n",
      "    return [x for x in arr if 'NN' in x[1]]\n",
      "\n",
      "def stripTags(arr):\n",
      "    for i, v in enumerate(arr):\n",
      "            arr[i] = strip_tags(v)\n",
      "            \n",
      "# Remove menu items\n",
      "RegxStripAnchors = re.compile(r'</?[aA].*\\>[^>]*/?>', re.DOTALL)\n",
      "RegxWhiteSpace = re.compile(r'\\S')\n",
      "def removeMenuItems(x):\n",
      "    substituted = re.sub(RegxStripAnchors, '', x)\n",
      "    striped_tags = strip_tags(substituted)\n",
      "    if re.search(RegxWhiteSpace, striped_tags):\n",
      "        return x\n",
      "    else:\n",
      "        return ''\n",
      "    \n",
      "def printList(arr, **kwargs):\n",
      "    label = kwargs.get('label', None)\n",
      "    ofset = kwargs.get('ofset', 0)\n",
      "    print '   '*ofset,label.encode('utf-8')\n",
      "    for v in arr:\n",
      "        print '   '*(ofset+1), '- ',v.encode('utf-8')\n",
      "    return\n",
      "\n",
      "validFilenameChars = \"-_.() %s%s\" % (string.ascii_letters, string.digits)\n",
      "def removeDisallowedFilenameChars(filename):\n",
      "    cleanedFilename = unicodedata.normalize('NFKD', filename).encode('ASCII', 'ignore')\n",
      "    return ''.join(c for c in cleanedFilename if c in validFilenameChars)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def processURL(url):\n",
      "    response = urllib2.urlopen(url)\n",
      "    html = response.read()\n",
      "\n",
      "    ttitle = Selector(text=html).xpath('//title/text()').extract()\n",
      "    th1 = Selector(text=html).xpath('//div/h1').extract()\n",
      "    th2 = Selector(text=html).xpath('//div/h2').extract()\n",
      "    th3 = Selector(text=html).xpath('//div/h3').extract()\n",
      "    th4 = Selector(text=html).xpath('//div/h4').extract()\n",
      "\n",
      "    tp = Selector(text=html).xpath('//p').extract()\n",
      "    tdiv = Selector(text=html).xpath('//div/text()').extract()\n",
      "\n",
      "    stripTags(th1)\n",
      "    stripTags(th2)\n",
      "    stripTags(th3)\n",
      "    stripTags(th4)\n",
      "    stripTags(tp)\n",
      "    stripTags(tdiv)\n",
      "\n",
      "    tli = Selector(text=html).xpath('//li').extract()\n",
      "    tli = map(lambda x: removeMenuItems(x), tli)\n",
      "    stripTags(tli)\n",
      "\n",
      "    #\u00a0Combine arrays\n",
      "    text = th1 + th2 + th3 + th4 + tp + tli + tdiv \n",
      "    text = [x for x in text if re.search(RegxWhiteSpace, x)]\n",
      "    text = '. '.join(text)\n",
      "\n",
      "    tokens = nltk.word_tokenize(text)\n",
      "    tagged = nltk.pos_tag(tokens)\n",
      "\n",
      "    nouns = getNouns(tagged)\n",
      "    nounsFreq = nltk.FreqDist(word for (word, tag) in nouns)\n",
      "    nounsFreqTop = nounsFreq.most_common(25)\n",
      "\n",
      "    ta = Selector(text=html).xpath('//a').extract()\n",
      "    links = []\n",
      "    RegxAnchor = re.compile(r'<?[aA].*href=\"([^\"]+)\".*\\>([^>]*)</a>', re.DOTALL);\n",
      "    for a in ta:\n",
      "        matches = re.search(RegxAnchor, a)\n",
      "        if (matches):\n",
      "            links.append((matches.group(1), matches.group(2))) \n",
      "\n",
      "    f = open('out/'+removeDisallowedFilenameChars(url)+'.txt', 'w')\n",
      "    original_out = sys.stdout\n",
      "    sys.stdout = f\n",
      "\n",
      "    print 'Title:'\n",
      "    print '   - ', ttitle[0].encode('utf-8')\n",
      "    print '\\n'\n",
      "\n",
      "    print 'Headlines:'\n",
      "    printList(th1, label='H1:', ofset=1)\n",
      "    printList(th2, label='H2:', ofset=1)\n",
      "    printList(th3, label='H3:', ofset=1)\n",
      "    printList(th3, label='H4:', ofset=1)\n",
      "    print '\\n'\n",
      "\n",
      "    print 'Nouns (',len(nouns),'):'\n",
      "    for word, count in nounsFreqTop:\n",
      "        print '  ', count, '\\t', word.encode('utf-8')\n",
      "    print '\\n'\n",
      "\n",
      "    print 'Links (',len(links),'):'\n",
      "    for url, title in links:\n",
      "        print '   - ', url.ljust(70).encode('utf-8'), title.encode('utf-8')\n",
      "    print '\\n'\n",
      "\n",
      "    sys.stdout = original_out\n",
      "    f.close()\n",
      "    \n",
      "    return nouns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "response = urllib2.urlopen('http://www.mgcgroup.cz/sitemap.xml')\n",
      "html = response.read()\n",
      "\n",
      "locs = Selector(text=html).xpath('//loc').extract()\n",
      "stripTags(locs)\n",
      "\n",
      "urls = []\n",
      "pagesNouns = []\n",
      "for l in locs:\n",
      "    if '/en/' in l:\n",
      "        urls.append(l)\n",
      "\n",
      "for u in urls:\n",
      "    nouns = processURL(u)\n",
      "    pagesNouns.append(nouns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allNouns = [item for sublist in pagesNouns for item in sublist]\n",
      "allNounsFreq = nltk.FreqDist(word for (word, tag) in allNouns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allNounsFreq.most_common(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "[(u'Group', 131),\n",
        " (u'MgC', 131),\n",
        " (u'\\u2013', 94),\n",
        " (u'development', 70),\n",
        " (u'consultant', 52),\n",
        " (u'trainer', 51),\n",
        " (u'management', 50),\n",
        " (u'training', 47),\n",
        " (u'Management', 47),\n",
        " (u'program', 46),\n",
        " (u'(', 45),\n",
        " (u'Czech', 43),\n",
        " (u'Sales', 43),\n",
        " (u'skills', 39),\n",
        " (u'University', 39),\n",
        " (u'experience', 39),\n",
        " (u')', 39),\n",
        " (u'sales', 34),\n",
        " (u'Communication', 34),\n",
        " (u'communication', 33),\n",
        " (u'trainings', 33),\n",
        " (u'manager', 32),\n",
        " (u'Marketing', 30),\n",
        " (u'topics', 28),\n",
        " (u'/', 26),\n",
        " (u'business', 25),\n",
        " (u'a.s.', 25),\n",
        " (u'Interests', 24),\n",
        " (u'References', 24),\n",
        " (u'Skills', 23),\n",
        " (u'practice', 23),\n",
        " (u'Seminars', 23),\n",
        " (u'Coaching', 22),\n",
        " (u'Negotiation', 22),\n",
        " (u'Prague', 21),\n",
        " (u'methods', 21),\n",
        " (u'Business', 21),\n",
        " (u'education', 20),\n",
        " (u'Basics', 19),\n",
        " (u'company', 19),\n",
        " (u's.r.o', 19),\n",
        " (u'marketing', 18),\n",
        " (u'Republic', 18),\n",
        " (u'team', 18),\n",
        " (u'Trainer', 17),\n",
        " (u'favorite', 17),\n",
        " (u'Shadowing', 17),\n",
        " (u'Development', 17),\n",
        " (u'Independent', 16),\n",
        " (u'Techniques', 16)]"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}